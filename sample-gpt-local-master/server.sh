python -m llama_cpp.server --model "./models/mistral-7b-openorca.Q4_0.gguf" --chat_format chatml --n_gpu_layers 1

python -m llama_cpp.server --model "D:\Download\chatgpt-streamlit-master\sample-gpt-local-master\models\mistral-7b-openorca.Q4_0.gguf" --chat_format chatml --n_gpu_layers 1 --host 127.0.0.1 --port 8005
